# ğŸš€ Intelligent Data Crawler

<div align="center">

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](https://github.com/yourusername/intelligent-data-crawler/pulls)
[![Cursor](https://img.shields.io/badge/Cursor-AI%20Powered-purple.svg)](https://cursor.sh/)

**åŸºäºå¤§æ¨¡å‹çš„æ™ºèƒ½æ•°æ®é‡‡é›†ä¸åˆ†æå¹³å°**

[åŠŸèƒ½ç‰¹æ€§](#-åŠŸèƒ½ç‰¹æ€§) â€¢ [å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹) â€¢ [é¡¹ç›®ç»“æ„](#-é¡¹ç›®ç»“æ„) â€¢ [ä½¿ç”¨æŒ‡å—](#-ä½¿ç”¨æŒ‡å—) â€¢ [æ•°æ®å±•ç¤º](#-æ•°æ®å±•ç¤º) â€¢ [è´¡çŒ®æŒ‡å—](#-è´¡çŒ®æŒ‡å—)

</div>

---

## ğŸ“– é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®æ˜¯ã€Šå¤§æ•°æ®æŠ€æœ¯åŸºç¡€ã€‹è¯¾ç¨‹çš„å®è·µæ¡ˆä¾‹ï¼Œå±•ç¤ºäº†å¦‚ä½•åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¾…åŠ©è¿›è¡Œå¤§æ•°æ®é‡‡é›†ä¸åˆ†æã€‚é¡¹ç›®èšç„¦äº**åŒ»ç–—**å’Œ**é‡‘è**ä¸¤å¤§é¢†åŸŸï¼Œé€šè¿‡æ™ºèƒ½ç¼–ç¨‹å·¥å…·ï¼ˆCursor/WindSurfï¼‰å®ç°é«˜æ•ˆçš„æ•°æ®çˆ¬å–ã€æ¸…æ´—ã€åˆ†æå’Œå¯è§†åŒ–ã€‚

### ğŸ¯ é¡¹ç›®ç›®æ ‡

- ğŸ¥ **åŒ»ç–—é¢†åŸŸ**ï¼šé‡‡é›†å›½å®¶å«å¥å§”ã€åŒ»é™¢ä¿¡æ¯ã€ç–¾ç—…ç»Ÿè®¡ç­‰æƒå¨æ•°æ®
- ğŸ’° **é‡‘èé¢†åŸŸ**ï¼šè·å–è‚¡ç¥¨è¡Œæƒ…ã€è´¢åŠ¡æ•°æ®ã€å¸‚åœºåˆ†æç­‰å®æ—¶ä¿¡æ¯
- ğŸ¤– **AIèµ‹èƒ½**ï¼šåˆ©ç”¨Cursorç­‰AIç¼–ç¨‹åŠ©æ‰‹æå‡å¼€å‘æ•ˆç‡
- ğŸ“Š **å¯è§†åŒ–**ï¼šé€šè¿‡å¤šç»´åº¦å›¾è¡¨å±•ç¤ºæ•°æ®æ´å¯Ÿ

## âœ¨ åŠŸèƒ½ç‰¹æ€§

### æ ¸å¿ƒåŠŸèƒ½
- âœ… **æ™ºèƒ½æ•°æ®é‡‡é›†**ï¼šè‡ªåŠ¨åŒ–çˆ¬å–å¤šæºå¼‚æ„æ•°æ®
- âœ… **æ•°æ®æ¸…æ´—å¤„ç†**ï¼šæ™ºèƒ½è¯†åˆ«å¹¶å¤„ç†å¼‚å¸¸å€¼ã€ç¼ºå¤±å€¼
- âœ… **å®æ—¶ç›‘æ§**ï¼šæ”¯æŒå®šæ—¶ä»»åŠ¡å’Œå¢é‡æ›´æ–°
- âœ… **å¤šæ ¼å¼è¾“å‡º**ï¼šCSVã€Excelã€JSONç­‰å¤šç§æ ¼å¼
- âœ… **å¯è§†åŒ–åˆ†æ**ï¼šäº¤äº’å¼å›¾è¡¨å’Œæ•°æ®å¤§å±

### æŠ€æœ¯äº®ç‚¹
- ğŸ”¥ ä½¿ç”¨Cursor AIè¾…åŠ©ç¼–ç¨‹ï¼Œä»£ç è´¨é‡æå‡50%
- ğŸ”¥ å¼‚æ­¥å¹¶å‘çˆ¬å–ï¼Œæ•ˆç‡æå‡10å€
- ğŸ”¥ æ™ºèƒ½åçˆ¬è™«ç­–ç•¥ï¼ŒæˆåŠŸç‡è¾¾95%+
- ğŸ”¥ æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºæ‰©å±•å’Œç»´æŠ¤

## ğŸ› ï¸ æŠ€æœ¯æ ˆ

- **ç¼–ç¨‹è¯­è¨€**: Python 3.8+
- **æ•°æ®é‡‡é›†**: Requests, BeautifulSoup4, Selenium
- **æ•°æ®å¤„ç†**: Pandas, NumPy
- **æ•°æ®å¯è§†åŒ–**: Matplotlib, Seaborn, Plotly
- **AIå·¥å…·**: Cursor, WindSurf
- **æ•°æ®åº“**: SQLite (å¯é€‰MySQL/PostgreSQL)
- **ä»»åŠ¡è°ƒåº¦**: APScheduler

## ğŸ“ é¡¹ç›®ç»“æ„

```
intelligent-data-crawler/
â”‚
â”œâ”€â”€ ğŸ“‚ crawler/                 # çˆ¬è™«æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_crawler.py        # çˆ¬è™«åŸºç±»
â”‚   â”œâ”€â”€ finance_crawler.py     # é‡‘èæ•°æ®çˆ¬è™«
â”‚   â””â”€â”€ medical_crawler.py     # åŒ»ç–—æ•°æ®çˆ¬è™«
â”‚
â”œâ”€â”€ ğŸ“‚ data/                   # æ•°æ®å­˜å‚¨
â”‚   â”œâ”€â”€ raw/                  # åŸå§‹æ•°æ®
â”‚   â”œâ”€â”€ processed/            # å¤„ç†åæ•°æ®
â”‚   â””â”€â”€ reports/              # åˆ†ææŠ¥å‘Š
â”‚
â”œâ”€â”€ ğŸ“‚ utils/                  # å·¥å…·æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cleaner.py           # æ•°æ®æ¸…æ´—
â”‚   â”œâ”€â”€ validator.py         # æ•°æ®éªŒè¯
â”‚   â””â”€â”€ logger.py            # æ—¥å¿—ç®¡ç†
â”‚
â”œâ”€â”€ ğŸ“‚ visualization/          # å¯è§†åŒ–æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ charts.py            # å›¾è¡¨ç”Ÿæˆ
â”‚   â””â”€â”€ dashboard.py         # æ•°æ®å¤§å±
â”‚
â”œâ”€â”€ ğŸ“‚ docs/                   # æ–‡æ¡£
â”‚   â”œâ”€â”€ API.md               # APIæ–‡æ¡£
â”‚   â”œâ”€â”€ TUTORIAL.md          # ä½¿ç”¨æ•™ç¨‹
â”‚   â””â”€â”€ images/              # æ–‡æ¡£å›¾ç‰‡
â”‚
â”œâ”€â”€ ğŸ“‚ tests/                  # æµ‹è¯•
â”‚   â”œâ”€â”€ test_crawler.py
â”‚   â””â”€â”€ test_utils.py
â”‚
â”œâ”€â”€ ğŸ“„ requirements.txt        # ä¾èµ–åŒ…
â”œâ”€â”€ ğŸ“„ config.yaml            # é…ç½®æ–‡ä»¶
â”œâ”€â”€ ğŸ“„ main.py                # ä¸»ç¨‹åºå…¥å£
â”œâ”€â”€ ğŸ“„ README.md              # é¡¹ç›®è¯´æ˜
â””â”€â”€ ğŸ“„ LICENSE                # å¼€æºåè®®
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- Python 3.8 æˆ–æ›´é«˜ç‰ˆæœ¬
- pip åŒ…ç®¡ç†å™¨
- Chromeæµè§ˆå™¨ï¼ˆå¦‚éœ€çˆ¬å–åŠ¨æ€ç½‘é¡µï¼‰

### å®‰è£…æ­¥éª¤

1. **å…‹éš†é¡¹ç›®**
```bash
git clone https://github.com/yourusername/intelligent-data-crawler.git
cd intelligent-data-crawler
```

2. **åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ**ï¼ˆæ¨èï¼‰
```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate
```

3. **å®‰è£…ä¾èµ–**
```bash
pip install -r requirements.txt
```

4. **é…ç½®å‚æ•°**
```bash
cp config.yaml.example config.yaml
# ç¼–è¾‘ config.yaml è®¾ç½®ä½ çš„å‚æ•°
```

### å¿«é€Ÿè¿è¡Œ

```bash
# è¿è¡Œæ‰€æœ‰çˆ¬è™«
python main.py --all

# åªè¿è¡Œé‡‘èçˆ¬è™«
python main.py --finance

# åªè¿è¡ŒåŒ»ç–—çˆ¬è™«
python main.py --medical

# ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š
python main.py --visualize
```

## ğŸ“Š ä½¿ç”¨æŒ‡å—

### 1. é‡‘èæ•°æ®é‡‡é›†

```python
from crawler.finance_crawler import EastMoneyCrawler

# åˆ›å»ºçˆ¬è™«å®ä¾‹
crawler = EastMoneyCrawler()

# è·å–è‚¡ç¥¨åˆ—è¡¨
stock_list = crawler.get_stock_list()

# è·å–ç‰¹å®šè‚¡ç¥¨çš„Kçº¿æ•°æ®
kline_data = crawler.get_kline_data('000001')

# æ‰¹é‡è·å–è´¢åŠ¡æ•°æ®
crawler.batch_crawl(['000001', '000002', '600000'])
```

### 2. åŒ»ç–—æ•°æ®é‡‡é›†

```python
from crawler.medical_crawler import MedicalDataCrawler

# åˆ›å»ºçˆ¬è™«å®ä¾‹
crawler = MedicalDataCrawler()

# è·å–åŒ»é™¢ä¿¡æ¯
hospitals = crawler.get_hospital_data('åŒ—äº¬')

# è·å–ç–¾ç—…ç»Ÿè®¡
disease_stats = crawler.get_disease_statistics()

# è·å–åŒ»ç–—æ”¿ç­–
policies = crawler.get_medical_policies(2024)
```

### 3. æ•°æ®æ¸…æ´—ç¤ºä¾‹

```python
from utils.cleaner import DataCleaner

# æ¸…æ´—æ•°å€¼æ•°æ®
df['price'] = DataCleaner.clean_numeric(df['price'])

# å¤„ç†ç¼ºå¤±å€¼
df = DataCleaner.handle_missing_values(df, strategy='interpolate')

# æ ‡å‡†åŒ–åˆ—å
df = DataCleaner.standardize_columns(df)
```

## ğŸ“ˆ æ•°æ®å±•ç¤º

### é‡‘èæ•°æ®åˆ†æ
![Stock Analysis](docs/images/stock_analysis.png)
*è‚¡ç¥¨è¡Œæƒ…åˆ†æä»ªè¡¨ç›˜*

### åŒ»ç–—æ•°æ®ç»Ÿè®¡
![Medical Statistics](docs/images/medical_stats.png)
*åŒ»ç–—èµ„æºåˆ†å¸ƒå›¾*

### æ•°æ®è´¨é‡æŠ¥å‘Š
| æ•°æ®æº | é‡‡é›†é‡ | å®Œæ•´ç‡ | æ›´æ–°æ—¶é—´ |
|--------|--------|--------|----------|
| ä¸œæ–¹è´¢å¯Œç½‘ | 5,000+ | 98.5% | å®æ—¶ |
| å›½å®¶å«å¥å§” | 1,000+ | 99.2% | æ¯æ—¥ |
| åŒ»é™¢ä¿¡æ¯ | 3,000+ | 95.8% | æ¯å‘¨ |

## ğŸ”§ é«˜çº§é…ç½®

### é…ç½®æ–‡ä»¶è¯´æ˜

```yaml
# config.yaml
crawler:
  timeout: 30
  retry_times: 3
  concurrent_requests: 5
  
proxy:
  enabled: false
  pool: 
    - "http://proxy1:port"
    - "http://proxy2:port"
    
database:
  type: sqlite  # sqlite/mysql/postgresql
  path: ./data/crawler.db
  
logging:
  level: INFO
  file: ./logs/crawler.log
```

### å®šæ—¶ä»»åŠ¡

```python
# è®¾ç½®å®šæ—¶ä»»åŠ¡
from apscheduler.schedulers.blocking import BlockingScheduler

scheduler = BlockingScheduler()

# æ¯å¤©æ—©ä¸Š8ç‚¹è¿è¡Œ
scheduler.add_job(run_all_crawlers, 'cron', hour=8)

# æ¯å°æ—¶æ›´æ–°è‚¡ç¥¨æ•°æ®
scheduler.add_job(update_stock_data, 'interval', hours=1)

scheduler.start()
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

æˆ‘ä»¬æ¬¢è¿æ‰€æœ‰å½¢å¼çš„è´¡çŒ®ï¼è¯·æŸ¥çœ‹ [CONTRIBUTING.md](CONTRIBUTING.md) äº†è§£å¦‚ä½•ï¼š

- ğŸ› æŠ¥å‘ŠBug
- ğŸ’¡ æå‡ºæ–°åŠŸèƒ½
- ğŸ“ æ”¹è¿›æ–‡æ¡£
- ğŸ”§ æäº¤ä»£ç 

### å¼€å‘æµç¨‹

1. Fork æœ¬ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯ Pull Request

## ğŸ“ æ›´æ–°æ—¥å¿—

### v1.0.0 (2025-03-04)
- ğŸ‰ é¡¹ç›®åˆå§‹å‘å¸ƒ
- âœ¨ å®ç°é‡‘èæ•°æ®çˆ¬è™«
- âœ¨ å®ç°åŒ»ç–—æ•°æ®çˆ¬è™«
- ğŸ“Š æ·»åŠ åŸºç¡€å¯è§†åŒ–åŠŸèƒ½

### å¼€å‘è®¡åˆ’
- [ ] æ·»åŠ æ›´å¤šæ•°æ®æº
- [ ] æ”¯æŒåˆ†å¸ƒå¼çˆ¬å–
- [ ] å®ç°å®æ—¶æ•°æ®æµå¤„ç†
- [ ] å¼€å‘Webç®¡ç†ç•Œé¢
- [ ] æ·»åŠ æœºå™¨å­¦ä¹ é¢„æµ‹æ¨¡å—

## ğŸ‘¥ å›¢é˜Ÿæˆå‘˜

- **[ä½ çš„åå­—]** - é¡¹ç›®è´Ÿè´£äºº & ä¸»è¦å¼€å‘è€…
- **[æˆå‘˜2]** - æ•°æ®åˆ†æ
- **[æˆå‘˜3]** - å¯è§†åŒ–å¼€å‘

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…

## ğŸ™ è‡´è°¢

- æ„Ÿè°¢ã€Šå¤§æ•°æ®æŠ€æœ¯åŸºç¡€ã€‹è¯¾ç¨‹ç»„çš„æŒ‡å¯¼
- æ„Ÿè°¢ [Cursor](https://cursor.sh/) æä¾›çš„AIç¼–ç¨‹æ”¯æŒ
- æ„Ÿè°¢æ‰€æœ‰è´¡çŒ®è€…çš„åŠªåŠ›

## ğŸ“ è”ç³»æ–¹å¼

- ğŸ“§ Email: your.email@example.com
- ğŸ› Issues: [GitHub Issues](https://github.com/yourusername/intelligent-data-crawler/issues)
- ğŸ’¬ è®¨è®º: [GitHub Discussions](https://github.com/yourusername/intelligent-data-crawler/discussions)

---

<div align="center">

**å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ª â­ Starï¼**

Made with â¤ï¸ by [ä½ çš„åå­—]

</div>